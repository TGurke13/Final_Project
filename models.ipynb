{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\thoma\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thoma\\AppData\\Local\\Temp\\ipykernel_21148\\3333390851.py:10: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  import kerastuner as kt\n"
     ]
    }
   ],
   "source": [
    " # Import Modules \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import kerastuner as kt\n",
    "from mmdata import * \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>TEAM NO</th>\n",
       "      <th>SEED</th>\n",
       "      <th>ROUND</th>\n",
       "      <th>POWER RATING</th>\n",
       "      <th>POWER RATING RANK</th>\n",
       "      <th>NET RPI</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>WAB RANK</th>\n",
       "      <th>...</th>\n",
       "      <th>POWER-PATH</th>\n",
       "      <th>SEED WON</th>\n",
       "      <th>SEED LOST</th>\n",
       "      <th>SEED DIFF</th>\n",
       "      <th>FIRST ROUND</th>\n",
       "      <th>SECOND ROUND</th>\n",
       "      <th>SWEET 16</th>\n",
       "      <th>ELITE 8</th>\n",
       "      <th>FINAL 4</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>603</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>89.0</td>\n",
       "      <td>59</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>119</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Austin Peay</td>\n",
       "      <td>602</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>68.8</td>\n",
       "      <td>462</td>\n",
       "      <td>189</td>\n",
       "      <td>218</td>\n",
       "      <td>229</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.8</td>\n",
       "      <td>119</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>601</td>\n",
       "      <td>5</td>\n",
       "      <td>64</td>\n",
       "      <td>85.5</td>\n",
       "      <td>152</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>22</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>119</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>Buffalo</td>\n",
       "      <td>600</td>\n",
       "      <td>14</td>\n",
       "      <td>64</td>\n",
       "      <td>75.7</td>\n",
       "      <td>396</td>\n",
       "      <td>91</td>\n",
       "      <td>112</td>\n",
       "      <td>129</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.4</td>\n",
       "      <td>119</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Butler</td>\n",
       "      <td>599</td>\n",
       "      <td>9</td>\n",
       "      <td>32</td>\n",
       "      <td>84.2</td>\n",
       "      <td>194</td>\n",
       "      <td>56</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>119</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2021</td>\n",
       "      <td>Oregon St.</td>\n",
       "      <td>830</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>79.7</td>\n",
       "      <td>332</td>\n",
       "      <td>91</td>\n",
       "      <td>32</td>\n",
       "      <td>47</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>2021</td>\n",
       "      <td>USC</td>\n",
       "      <td>817</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>85.8</td>\n",
       "      <td>143</td>\n",
       "      <td>19</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>2021</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>872</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>86.3</td>\n",
       "      <td>129</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>2021</td>\n",
       "      <td>UCLA</td>\n",
       "      <td>819</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>81.9</td>\n",
       "      <td>267</td>\n",
       "      <td>46</td>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>2021</td>\n",
       "      <td>Houston</td>\n",
       "      <td>853</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR         TEAM  TEAM NO  SEED  ROUND  POWER RATING  POWER RATING RANK  \\\n",
       "0    2016      Arizona      603     6     64          89.0                 59   \n",
       "1    2016  Austin Peay      602    16     64          68.8                462   \n",
       "2    2016       Baylor      601     5     64          85.5                152   \n",
       "3    2016      Buffalo      600    14     64          75.7                396   \n",
       "4    2016       Butler      599     9     32          84.2                194   \n",
       "..    ...          ...      ...   ...    ...           ...                ...   \n",
       "779  2021   Oregon St.      830    12      8          79.7                332   \n",
       "780  2021          USC      817     6      8          85.8                143   \n",
       "781  2021     Arkansas      872     3      8          86.3                129   \n",
       "782  2021         UCLA      819    11      4          81.9                267   \n",
       "783  2021      Houston      853     2      4          90.6                 40   \n",
       "\n",
       "     NET RPI  RESUME  WAB RANK  ...  POWER-PATH  SEED WON  SEED LOST  \\\n",
       "0         26      27        23  ...         4.4       119         51   \n",
       "1        189     218       229  ...       -41.8       119         51   \n",
       "2         25      25        22  ...         5.1       119         51   \n",
       "3         91     112       129  ...       -24.4       119         51   \n",
       "4         56      29        32  ...        -3.5       119         51   \n",
       "..       ...     ...       ...  ...         ...       ...        ...   \n",
       "779       91      32        47  ...       -19.5        11          1   \n",
       "780       19      37         7  ...         7.5        11          1   \n",
       "781       14      20        12  ...         7.6        11          1   \n",
       "782       46      55        24  ...        -6.8        11          1   \n",
       "783        5      50        15  ...        21.0        11          1   \n",
       "\n",
       "     SEED DIFF  FIRST ROUND  SECOND ROUND  SWEET 16  ELITE 8  FINAL 4  TOTAL  \n",
       "0           68           10             2         0        1        0     13  \n",
       "1           68           10             2         0        1        0     13  \n",
       "2           68           10             2         0        1        0     13  \n",
       "3           68           10             2         0        1        0     13  \n",
       "4           68           10             2         0        1        0     13  \n",
       "..         ...          ...           ...       ...      ...      ...    ...  \n",
       "779         10            9             6         2        1        0     18  \n",
       "780         10            9             6         2        1        0     18  \n",
       "781         10            9             6         2        1        0     18  \n",
       "782         10            9             6         2        1        0     18  \n",
       "783         10            9             6         2        1        0     18  \n",
       "\n",
       "[784 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the final data csv\n",
    "data = pd.read_csv('final_data.csv')\n",
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'TEAM', 'TEAM NO', 'SEED', 'ROUND', 'POWER RATING',\n",
       "       'POWER RATING RANK', 'NET RPI', 'RESUME', 'WAB RANK', 'ELO', 'B POWER',\n",
       "       'Q1 W', 'Q2 W', 'Q1 PLUS Q2 W', 'Q3 Q4 L', 'PLUS 500', 'R SCORE',\n",
       "       'BY YEAR NO', 'BY ROUND NO', 'CURRENT ROUND', 'SCORE', 'PAKE',\n",
       "       'PAKE RANK', 'PASE', 'PASE RANK', 'GAMES', 'W', 'L', 'WIN%', 'R64',\n",
       "       'R32', 'S16', 'E8', 'F4', 'F2', 'CHAMP', 'TOP2', 'F4%', 'CHAMP%',\n",
       "       'POWER', 'PATH', 'DRAW', 'WINS', 'POOL VALUE', 'POOL S-RANK',\n",
       "       'NCAA S-RANK', 'VAL Z-SCORE', 'POWER-PATH', 'SEED WON', 'SEED LOST',\n",
       "       'SEED DIFF', 'FIRST ROUND', 'SECOND ROUND', 'SWEET 16', 'ELITE 8',\n",
       "       'FINAL 4', 'TOTAL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR                   int64\n",
      "TEAM                  object\n",
      "TEAM NO                int64\n",
      "SEED                   int64\n",
      "ROUND                  int64\n",
      "POWER RATING         float64\n",
      "POWER RATING RANK      int64\n",
      "NET RPI                int64\n",
      "RESUME                 int64\n",
      "WAB RANK               int64\n",
      "ELO                    int64\n",
      "B POWER              float64\n",
      "Q1 W                   int64\n",
      "Q2 W                   int64\n",
      "Q1 PLUS Q2 W           int64\n",
      "Q3 Q4 L                int64\n",
      "PLUS 500               int64\n",
      "R SCORE              float64\n",
      "BY YEAR NO             int64\n",
      "BY ROUND NO            int64\n",
      "CURRENT ROUND          int64\n",
      "SCORE                float64\n",
      "PAKE                 float64\n",
      "PAKE RANK              int64\n",
      "PASE                 float64\n",
      "PASE RANK              int64\n",
      "GAMES                  int64\n",
      "W                      int64\n",
      "L                      int64\n",
      "WIN%                 float64\n",
      "R64                    int64\n",
      "R32                    int64\n",
      "S16                    int64\n",
      "E8                     int64\n",
      "F4                     int64\n",
      "F2                     int64\n",
      "TOP2                   int64\n",
      "F4%                   object\n",
      "CHAMP%                object\n",
      "POWER                float64\n",
      "PATH                 float64\n",
      "DRAW                 float64\n",
      "WINS                   int64\n",
      "POOL VALUE           float64\n",
      "POOL S-RANK            int64\n",
      "NCAA S-RANK            int64\n",
      "VAL Z-SCORE          float64\n",
      "POWER-PATH           float64\n",
      "SEED WON               int64\n",
      "SEED LOST              int64\n",
      "SEED DIFF              int64\n",
      "FIRST ROUND            int64\n",
      "SECOND ROUND           int64\n",
      "SWEET 16               int64\n",
      "ELITE 8                int64\n",
      "FINAL 4                int64\n",
      "TOTAL                  int64\n",
      "dtype: object int64\n"
     ]
    }
   ],
   "source": [
    "# List features and target\n",
    "X = data.drop(columns='CHAMP')\n",
    "y = data['CHAMP']\n",
    "input_nodes = X.shape[1]\n",
    "print(X.dtypes, y.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode the data\n",
    "X_encoder = OneHotEncoder()\n",
    "y_encoder = LabelEncoder()\n",
    "\n",
    "X = X_encoder.fit_transform(X)\n",
    "y = y_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intialize and fit robust scaler... best for this data\n",
    "scaler = RobustScaler(with_centering=False)\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating a model with hyperparameters\n",
    "def create_model(hp):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    activation = hp.Choice('activation', values=['relu', 'tanh', 'sigmoid'])\n",
    "    # Decide number of neurons in each layer\n",
    "    model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "        min_value=32,\n",
    "        max_value=512,\n",
    "        step=32), activation=activation, input_dim=X.shape[1]))\n",
    "    # Decide number of hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "        model.add(tf.keras.layers.Dense(units=hp.Int(\n",
    "            f'layer_{i}_units',\n",
    "            min_value=32,\n",
    "            max_value=512,\n",
    "            step=32), activation=activation))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    # Compile the model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(create_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_epochs=100,\n",
    "                        hyperband_iterations=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train_scaled, y_train, epochs=100, validation_data=(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'first_units': 288,\n",
       " 'num_layers': 3,\n",
       " 'layer_0_units': 384,\n",
       " 'layer_1_units': 256,\n",
       " 'layer_2_units': 448,\n",
       " 'layer_3_units': 384,\n",
       " 'layer_4_units': 32,\n",
       " 'tuner/epochs': 2,\n",
       " 'tuner/initial_epoch': 0,\n",
       " 'tuner/bracket': 4,\n",
       " 'tuner/round': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "best_hps.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\thoma\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\thoma\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From c:\\Users\\thoma\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\thoma\\anaconda3\\envs\\dev\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "20/20 [==============================] - 1s 11ms/step - loss: -1.5463 - accuracy: 0.8565 - val_loss: -4.0001 - val_accuracy: 0.8854\n",
      "Epoch 2/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -3.5734 - accuracy: 0.9043 - val_loss: -5.2544 - val_accuracy: 0.8854\n",
      "Epoch 3/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -4.4875 - accuracy: 0.9043 - val_loss: -6.4255 - val_accuracy: 0.8854\n",
      "Epoch 4/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -5.3901 - accuracy: 0.9043 - val_loss: -7.5571 - val_accuracy: 0.8854\n",
      "Epoch 5/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -6.2365 - accuracy: 0.9043 - val_loss: -8.7158 - val_accuracy: 0.8854\n",
      "Epoch 6/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -7.1223 - accuracy: 0.9043 - val_loss: -9.7946 - val_accuracy: 0.8854\n",
      "Epoch 7/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -7.9363 - accuracy: 0.9043 - val_loss: -10.9107 - val_accuracy: 0.8854\n",
      "Epoch 8/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -8.8137 - accuracy: 0.9043 - val_loss: -11.9021 - val_accuracy: 0.8854\n",
      "Epoch 9/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -9.6189 - accuracy: 0.9043 - val_loss: -12.9939 - val_accuracy: 0.8854\n",
      "Epoch 10/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -10.4856 - accuracy: 0.9043 - val_loss: -14.0188 - val_accuracy: 0.8854\n",
      "Epoch 11/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -11.2574 - accuracy: 0.9043 - val_loss: -15.1860 - val_accuracy: 0.8854\n",
      "Epoch 12/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -12.1403 - accuracy: 0.9043 - val_loss: -16.1748 - val_accuracy: 0.8854\n",
      "Epoch 13/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -12.9303 - accuracy: 0.9043 - val_loss: -17.2395 - val_accuracy: 0.8854\n",
      "Epoch 14/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -13.7562 - accuracy: 0.9043 - val_loss: -18.2579 - val_accuracy: 0.8854\n",
      "Epoch 15/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -14.5545 - accuracy: 0.9043 - val_loss: -19.3272 - val_accuracy: 0.8854\n",
      "Epoch 16/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -15.3732 - accuracy: 0.9043 - val_loss: -20.3823 - val_accuracy: 0.8854\n",
      "Epoch 17/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -16.2027 - accuracy: 0.9043 - val_loss: -21.4409 - val_accuracy: 0.8854\n",
      "Epoch 18/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -17.0192 - accuracy: 0.9043 - val_loss: -22.4792 - val_accuracy: 0.8854\n",
      "Epoch 19/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -17.8105 - accuracy: 0.9043 - val_loss: -23.5728 - val_accuracy: 0.8854\n",
      "Epoch 20/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -18.6529 - accuracy: 0.9043 - val_loss: -24.5910 - val_accuracy: 0.8854\n",
      "Epoch 21/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -19.4465 - accuracy: 0.9043 - val_loss: -25.6162 - val_accuracy: 0.8854\n",
      "Epoch 22/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -20.2475 - accuracy: 0.9043 - val_loss: -26.6472 - val_accuracy: 0.8854\n",
      "Epoch 23/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -21.0416 - accuracy: 0.9043 - val_loss: -27.6828 - val_accuracy: 0.8854\n",
      "Epoch 24/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -21.8517 - accuracy: 0.9043 - val_loss: -28.7401 - val_accuracy: 0.8854\n",
      "Epoch 25/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -22.6527 - accuracy: 0.9043 - val_loss: -29.7982 - val_accuracy: 0.8854\n",
      "Epoch 26/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -23.4798 - accuracy: 0.9043 - val_loss: -30.8615 - val_accuracy: 0.8854\n",
      "Epoch 27/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -24.2945 - accuracy: 0.9043 - val_loss: -31.9536 - val_accuracy: 0.8854\n",
      "Epoch 28/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -25.1310 - accuracy: 0.9043 - val_loss: -32.9673 - val_accuracy: 0.8854\n",
      "Epoch 29/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -25.9350 - accuracy: 0.9043 - val_loss: -34.0041 - val_accuracy: 0.8854\n",
      "Epoch 30/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -26.7332 - accuracy: 0.9043 - val_loss: -35.0596 - val_accuracy: 0.8854\n",
      "Epoch 31/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -27.5417 - accuracy: 0.9043 - val_loss: -36.1280 - val_accuracy: 0.8854\n",
      "Epoch 32/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -28.3640 - accuracy: 0.9043 - val_loss: -37.1586 - val_accuracy: 0.8854\n",
      "Epoch 33/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -29.1457 - accuracy: 0.9043 - val_loss: -38.2589 - val_accuracy: 0.8854\n",
      "Epoch 34/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -30.0074 - accuracy: 0.9043 - val_loss: -39.2144 - val_accuracy: 0.8854\n",
      "Epoch 35/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -30.7928 - accuracy: 0.9043 - val_loss: -40.2893 - val_accuracy: 0.8854\n",
      "Epoch 36/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -31.6168 - accuracy: 0.9043 - val_loss: -41.3437 - val_accuracy: 0.8854\n",
      "Epoch 37/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -32.4381 - accuracy: 0.9043 - val_loss: -42.3852 - val_accuracy: 0.8854\n",
      "Epoch 38/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -33.2190 - accuracy: 0.9043 - val_loss: -43.4976 - val_accuracy: 0.8854\n",
      "Epoch 39/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -34.0633 - accuracy: 0.9043 - val_loss: -44.5066 - val_accuracy: 0.8854\n",
      "Epoch 40/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -34.8557 - accuracy: 0.9043 - val_loss: -45.5530 - val_accuracy: 0.8854\n",
      "Epoch 41/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -35.6807 - accuracy: 0.9043 - val_loss: -46.5976 - val_accuracy: 0.8854\n",
      "Epoch 42/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -36.4865 - accuracy: 0.9043 - val_loss: -47.6464 - val_accuracy: 0.8854\n",
      "Epoch 43/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -37.3074 - accuracy: 0.9043 - val_loss: -48.6864 - val_accuracy: 0.8854\n",
      "Epoch 44/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -38.1079 - accuracy: 0.9043 - val_loss: -49.7461 - val_accuracy: 0.8854\n",
      "Epoch 45/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -38.9345 - accuracy: 0.9043 - val_loss: -50.7618 - val_accuracy: 0.8854\n",
      "Epoch 46/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -39.7334 - accuracy: 0.9043 - val_loss: -51.8637 - val_accuracy: 0.8854\n",
      "Epoch 47/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -40.5782 - accuracy: 0.9043 - val_loss: -52.8723 - val_accuracy: 0.8854\n",
      "Epoch 48/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -41.3574 - accuracy: 0.9043 - val_loss: -53.9741 - val_accuracy: 0.8854\n",
      "Epoch 49/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -42.1792 - accuracy: 0.9043 - val_loss: -55.0252 - val_accuracy: 0.8854\n",
      "Epoch 50/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -42.9970 - accuracy: 0.9043 - val_loss: -56.0741 - val_accuracy: 0.8854\n",
      "Epoch 51/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -43.8335 - accuracy: 0.9043 - val_loss: -57.0793 - val_accuracy: 0.8854\n",
      "Epoch 52/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -44.6238 - accuracy: 0.9043 - val_loss: -58.1667 - val_accuracy: 0.8854\n",
      "Epoch 53/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -45.4288 - accuracy: 0.9043 - val_loss: -59.2298 - val_accuracy: 0.8854\n",
      "Epoch 54/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -46.2428 - accuracy: 0.9043 - val_loss: -60.2940 - val_accuracy: 0.8854\n",
      "Epoch 55/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -47.0823 - accuracy: 0.9043 - val_loss: -61.2633 - val_accuracy: 0.8854\n",
      "Epoch 56/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -47.8359 - accuracy: 0.9043 - val_loss: -62.3613 - val_accuracy: 0.8854\n",
      "Epoch 57/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -48.6916 - accuracy: 0.9043 - val_loss: -63.3670 - val_accuracy: 0.8854\n",
      "Epoch 58/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -49.4934 - accuracy: 0.9043 - val_loss: -64.4119 - val_accuracy: 0.8854\n",
      "Epoch 59/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -50.3159 - accuracy: 0.9043 - val_loss: -65.4466 - val_accuracy: 0.8854\n",
      "Epoch 60/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -51.1183 - accuracy: 0.9043 - val_loss: -66.5204 - val_accuracy: 0.8854\n",
      "Epoch 61/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -51.9177 - accuracy: 0.9043 - val_loss: -67.6157 - val_accuracy: 0.8854\n",
      "Epoch 62/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -52.7753 - accuracy: 0.9043 - val_loss: -68.6281 - val_accuracy: 0.8854\n",
      "Epoch 63/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -53.5800 - accuracy: 0.9043 - val_loss: -69.6411 - val_accuracy: 0.8854\n",
      "Epoch 64/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -54.3663 - accuracy: 0.9043 - val_loss: -70.7384 - val_accuracy: 0.8854\n",
      "Epoch 65/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -55.1857 - accuracy: 0.9043 - val_loss: -71.8270 - val_accuracy: 0.8854\n",
      "Epoch 66/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -56.0205 - accuracy: 0.9043 - val_loss: -72.8593 - val_accuracy: 0.8854\n",
      "Epoch 67/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -56.8434 - accuracy: 0.9043 - val_loss: -73.8324 - val_accuracy: 0.8854\n",
      "Epoch 68/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -57.6269 - accuracy: 0.9043 - val_loss: -74.8801 - val_accuracy: 0.8854\n",
      "Epoch 69/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -58.4486 - accuracy: 0.9043 - val_loss: -75.9441 - val_accuracy: 0.8854\n",
      "Epoch 70/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -59.2482 - accuracy: 0.9043 - val_loss: -77.0655 - val_accuracy: 0.8854\n",
      "Epoch 71/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -60.0754 - accuracy: 0.9043 - val_loss: -78.1131 - val_accuracy: 0.8854\n",
      "Epoch 72/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -60.9073 - accuracy: 0.9043 - val_loss: -79.1459 - val_accuracy: 0.8854\n",
      "Epoch 73/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -61.6972 - accuracy: 0.9043 - val_loss: -80.2164 - val_accuracy: 0.8854\n",
      "Epoch 74/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -62.5258 - accuracy: 0.9043 - val_loss: -81.2548 - val_accuracy: 0.8854\n",
      "Epoch 75/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -63.3450 - accuracy: 0.9043 - val_loss: -82.2869 - val_accuracy: 0.8854\n",
      "Epoch 76/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -64.1491 - accuracy: 0.9043 - val_loss: -83.3635 - val_accuracy: 0.8854\n",
      "Epoch 77/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -64.9993 - accuracy: 0.9043 - val_loss: -84.3782 - val_accuracy: 0.8854\n",
      "Epoch 78/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -65.8104 - accuracy: 0.9043 - val_loss: -85.4284 - val_accuracy: 0.8854\n",
      "Epoch 79/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -66.6274 - accuracy: 0.9043 - val_loss: -86.4980 - val_accuracy: 0.8854\n",
      "Epoch 80/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -67.4286 - accuracy: 0.9043 - val_loss: -87.5656 - val_accuracy: 0.8854\n",
      "Epoch 81/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -68.2477 - accuracy: 0.9043 - val_loss: -88.6215 - val_accuracy: 0.8854\n",
      "Epoch 82/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -69.0549 - accuracy: 0.9043 - val_loss: -89.6969 - val_accuracy: 0.8854\n",
      "Epoch 83/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -69.8601 - accuracy: 0.9043 - val_loss: -90.7668 - val_accuracy: 0.8854\n",
      "Epoch 84/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -70.6901 - accuracy: 0.9043 - val_loss: -91.7659 - val_accuracy: 0.8854\n",
      "Epoch 85/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -71.4906 - accuracy: 0.9043 - val_loss: -92.7795 - val_accuracy: 0.8854\n",
      "Epoch 86/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -72.2935 - accuracy: 0.9043 - val_loss: -93.8324 - val_accuracy: 0.8854\n",
      "Epoch 87/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -73.1086 - accuracy: 0.9043 - val_loss: -94.9092 - val_accuracy: 0.8854\n",
      "Epoch 88/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -73.9508 - accuracy: 0.9043 - val_loss: -95.9715 - val_accuracy: 0.8854\n",
      "Epoch 89/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -74.7590 - accuracy: 0.9043 - val_loss: -96.9994 - val_accuracy: 0.8854\n",
      "Epoch 90/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -75.5570 - accuracy: 0.9043 - val_loss: -98.0361 - val_accuracy: 0.8854\n",
      "Epoch 91/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -76.3800 - accuracy: 0.9043 - val_loss: -99.1066 - val_accuracy: 0.8854\n",
      "Epoch 92/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -77.1655 - accuracy: 0.9043 - val_loss: -100.2208 - val_accuracy: 0.8854\n",
      "Epoch 93/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -78.0125 - accuracy: 0.9043 - val_loss: -101.2435 - val_accuracy: 0.8854\n",
      "Epoch 94/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -78.7947 - accuracy: 0.9043 - val_loss: -102.3115 - val_accuracy: 0.8854\n",
      "Epoch 95/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -79.6378 - accuracy: 0.9043 - val_loss: -103.2782 - val_accuracy: 0.8854\n",
      "Epoch 96/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -80.4314 - accuracy: 0.9043 - val_loss: -104.2899 - val_accuracy: 0.8854\n",
      "Epoch 97/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -81.2035 - accuracy: 0.9043 - val_loss: -105.3873 - val_accuracy: 0.8854\n",
      "Epoch 98/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -82.0622 - accuracy: 0.9043 - val_loss: -106.3554 - val_accuracy: 0.8854\n",
      "Epoch 99/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -82.8498 - accuracy: 0.9043 - val_loss: -107.4621 - val_accuracy: 0.8854\n",
      "Epoch 100/100\n",
      "20/20 [==============================] - 0s 6ms/step - loss: -83.6675 - accuracy: 0.9043 - val_loss: -108.5521 - val_accuracy: 0.8854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2a184970ee0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model with the best hyperparameters\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "model.fit(X_train_scaled, y_train, epochs=100, validation_data=(X_test_scaled, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 - 0s - loss: -1.0855e+02 - accuracy: 0.8854 - 12ms/epoch - 2ms/step\n",
      "Loss: -108.55207824707031, Accuracy: 0.8853503465652466\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_loss, model_accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>TEAM NO</th>\n",
       "      <th>SEED</th>\n",
       "      <th>ROUND</th>\n",
       "      <th>POWER RATING</th>\n",
       "      <th>POWER RATING RANK</th>\n",
       "      <th>NET RPI</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>WAB RANK</th>\n",
       "      <th>...</th>\n",
       "      <th>POWER-PATH</th>\n",
       "      <th>SEED WON</th>\n",
       "      <th>SEED LOST</th>\n",
       "      <th>SEED DIFF</th>\n",
       "      <th>FIRST ROUND</th>\n",
       "      <th>SECOND ROUND</th>\n",
       "      <th>SWEET 16</th>\n",
       "      <th>ELITE 8</th>\n",
       "      <th>FINAL 4</th>\n",
       "      <th>TOTAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>2023</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1010</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>89.0</td>\n",
       "      <td>59</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>15.6</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>2023</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>1006</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>87.1</td>\n",
       "      <td>104</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>2023</td>\n",
       "      <td>Connecticut</td>\n",
       "      <td>1002</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>89.2</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>2023</td>\n",
       "      <td>Duke</td>\n",
       "      <td>999</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>87.1</td>\n",
       "      <td>104</td>\n",
       "      <td>16</td>\n",
       "      <td>28</td>\n",
       "      <td>16</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>2023</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>995</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>89.9</td>\n",
       "      <td>46</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>17.6</td>\n",
       "      <td>65</td>\n",
       "      <td>20</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>2023</td>\n",
       "      <td>Texas</td>\n",
       "      <td>957</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>90.1</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>14.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>2023</td>\n",
       "      <td>Creighton</td>\n",
       "      <td>1001</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>87.6</td>\n",
       "      <td>92</td>\n",
       "      <td>17</td>\n",
       "      <td>40</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>2023</td>\n",
       "      <td>Kansas St.</td>\n",
       "      <td>985</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>84.5</td>\n",
       "      <td>180</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>2023</td>\n",
       "      <td>San Diego St.</td>\n",
       "      <td>961</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>86.0</td>\n",
       "      <td>136</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>2023</td>\n",
       "      <td>Florida Atlantic</td>\n",
       "      <td>997</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>82.6</td>\n",
       "      <td>246</td>\n",
       "      <td>13</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     YEAR              TEAM  TEAM NO  SEED  ROUND  POWER RATING  \\\n",
       "460  2023           Arizona     1010     2     64          89.0   \n",
       "461  2023            Baylor     1006     3     32          87.1   \n",
       "462  2023       Connecticut     1002     4      1          89.2   \n",
       "463  2023              Duke      999     5     32          87.1   \n",
       "464  2023           Gonzaga      995     3      8          89.9   \n",
       "..    ...               ...      ...   ...    ...           ...   \n",
       "575  2023             Texas      957     2      8          90.1   \n",
       "576  2023         Creighton     1001     6      8          87.6   \n",
       "577  2023        Kansas St.      985     3      8          84.5   \n",
       "578  2023     San Diego St.      961     5      2          86.0   \n",
       "579  2023  Florida Atlantic      997     9      4          82.6   \n",
       "\n",
       "     POWER RATING RANK  NET RPI  RESUME  WAB RANK  ...  POWER-PATH  SEED WON  \\\n",
       "460                 59       10       7         7  ...        15.6        65   \n",
       "461                104       15       4        12  ...        12.0        65   \n",
       "462                 57        8      19        13  ...        14.5        65   \n",
       "463                104       16      28        16  ...         9.8        65   \n",
       "464                 46        6      17         9  ...        17.6        65   \n",
       "..                 ...      ...     ...       ...  ...         ...       ...   \n",
       "575                 43        7       2         8  ...        14.5        14   \n",
       "576                 92       17      40        29  ...         7.9        14   \n",
       "577                180       23       8        17  ...         6.9        14   \n",
       "578                136       14      26        10  ...         3.1        14   \n",
       "579                246       13      59        14  ...        -2.9        14   \n",
       "\n",
       "     SEED LOST  SEED DIFF  FIRST ROUND  SECOND ROUND  SWEET 16  ELITE 8  \\\n",
       "460         20         45            5             4         3        2   \n",
       "461         20         45            5             4         3        2   \n",
       "462         20         45            5             4         3        2   \n",
       "463         20         45            5             4         3        2   \n",
       "464         20         45            5             4         3        2   \n",
       "..         ...        ...          ...           ...       ...      ...   \n",
       "575          5          9            5             4         3        2   \n",
       "576          5          9            5             4         3        2   \n",
       "577          5          9            5             4         3        2   \n",
       "578          5          9            5             4         3        2   \n",
       "579          5          9            5             4         3        2   \n",
       "\n",
       "     FINAL 4  TOTAL  \n",
       "460        0     14  \n",
       "461        0     14  \n",
       "462        0     14  \n",
       "463        0     14  \n",
       "464        0     14  \n",
       "..       ...    ...  \n",
       "575        0     14  \n",
       "576        0     14  \n",
       "577        0     14  \n",
       "578        0     14  \n",
       "579        0     14  \n",
       "\n",
       "[120 rows x 58 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the 2024 champ\n",
    "# get the 2024 data from the csv\n",
    "data = pd.read_csv('final_data.csv')\n",
    "data_2024 = data.loc[data['YEAR'] == 2023]\n",
    "data_2024 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict the 2024 champ\n",
    "X_2024 = data_2024.drop(columns='CHAMP')\n",
    "X_2024 = X_encoder.fit_transform(X_2024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<120x1922 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6840 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thoma\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict the 2024 champ\n",
    "\n",
    "y_pred = model.predict(X_2024)\n",
    "y_pred = y_encoder.fit_transform(y_pred)\n",
    "y_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
