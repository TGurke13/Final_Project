{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import data\n",
    "\n",
    "# Import data from CSV files\n",
    "data = pd.read_csv('/Users/johnparentejr/Documents/Final_Project-main/FP1/MM_CSV/Resumes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEAM NO</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>ROUND</th>\n",
       "      <th>NET RPI</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>WAB RANK</th>\n",
       "      <th>ELO</th>\n",
       "      <th>B POWER</th>\n",
       "      <th>Q1 W</th>\n",
       "      <th>Q2 W</th>\n",
       "      <th>Q1 PLUS Q2 W</th>\n",
       "      <th>Q3 Q4 L</th>\n",
       "      <th>PLUS 500</th>\n",
       "      <th>R SCORE</th>\n",
       "      <th>BID TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1079</td>\n",
       "      <td>Akron</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>131</td>\n",
       "      <td>104</td>\n",
       "      <td>103</td>\n",
       "      <td>111.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>At-Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>1078</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>99.35</td>\n",
       "      <td>At-Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>1077</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>99.87</td>\n",
       "      <td>At-Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>1076</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>99.42</td>\n",
       "      <td>At-Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>1075</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>13.5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>99.73</td>\n",
       "      <td>At-Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>96.80</td>\n",
       "      <td>At-Large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>Western Kentucky</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>124</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.30</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>108</td>\n",
       "      <td>121</td>\n",
       "      <td>108</td>\n",
       "      <td>93</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>99.90</td>\n",
       "      <td>Auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>99.70</td>\n",
       "      <td>At-Large</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1079 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      YEAR  TEAM NO              TEAM  SEED  ROUND  NET RPI  RESUME  WAB RANK  \\\n",
       "0     2024     1079             Akron    14      0      106     131       104   \n",
       "1     2024     1078           Alabama     4      0       10      31        15   \n",
       "2     2024     1077           Arizona     2      0        4      10        11   \n",
       "3     2024     1076            Auburn     4      0        5      45         9   \n",
       "4     2024     1075            Baylor     3      0       13       8        10   \n",
       "...    ...      ...               ...   ...    ...      ...     ...       ...   \n",
       "1074  2008        5     West Virginia     7     16       29      32        28   \n",
       "1075  2008        4  Western Kentucky    12     16       39     124        46   \n",
       "1076  2008        3          Winthrop    13     64      108     121       108   \n",
       "1077  2008        2         Wisconsin     3     16       11       9         8   \n",
       "1078  2008        1            Xavier     3      8        9       7        18   \n",
       "\n",
       "      ELO  B POWER  Q1 W  Q2 W  Q1 PLUS Q2 W  Q3 Q4 L  PLUS 500  R SCORE  \\\n",
       "0     103    111.5     0     2             2        4        13     0.00   \n",
       "1      31     11.5     4     7            11        0        11    99.35   \n",
       "2      14      5.5     8     7            15        1        18    99.87   \n",
       "3       5      4.0     3    10            13        0        21    99.42   \n",
       "4      25     13.5    10     4            14        0        14    99.73   \n",
       "...   ...      ...   ...   ...           ...      ...       ...      ...   \n",
       "1074   29     20.0     3     2             5        1        13    96.80   \n",
       "1075   25     45.0     0     1             1        1        19     5.30   \n",
       "1076   93     96.0     1     2             3        7         9     0.00   \n",
       "1077    5      6.0     6     2             8        0        25    99.90   \n",
       "1078   13     13.0     9     3            12        0        21    99.70   \n",
       "\n",
       "      BID TYPE  \n",
       "0     At-Large  \n",
       "1     At-Large  \n",
       "2     At-Large  \n",
       "3     At-Large  \n",
       "4     At-Large  \n",
       "...        ...  \n",
       "1074  At-Large  \n",
       "1075      Auto  \n",
       "1076      Auto  \n",
       "1077      Auto  \n",
       "1078  At-Large  \n",
       "\n",
       "[1079 rows x 17 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Team Resume data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At-Large' 'Auto']\n"
     ]
    }
   ],
   "source": [
    "print(data['BID TYPE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert 'BID TYPE' column to binary values\n",
    "# Auto = 1, At-Large = 0\n",
    "data['BID TYPE'] = data['BID TYPE'].map({'Auto': 1, 'At-Large': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEAM NO</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>SEED</th>\n",
       "      <th>ROUND</th>\n",
       "      <th>NET RPI</th>\n",
       "      <th>RESUME</th>\n",
       "      <th>WAB RANK</th>\n",
       "      <th>ELO</th>\n",
       "      <th>B POWER</th>\n",
       "      <th>Q1 W</th>\n",
       "      <th>Q2 W</th>\n",
       "      <th>Q1 PLUS Q2 W</th>\n",
       "      <th>Q3 Q4 L</th>\n",
       "      <th>PLUS 500</th>\n",
       "      <th>R SCORE</th>\n",
       "      <th>BID TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>1079</td>\n",
       "      <td>Akron</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>131</td>\n",
       "      <td>104</td>\n",
       "      <td>103</td>\n",
       "      <td>111.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>1078</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>15</td>\n",
       "      <td>31</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>99.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>1077</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>5.5</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>1076</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>45</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>99.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>1075</td>\n",
       "      <td>Baylor</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>13.5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>99.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>2008</td>\n",
       "      <td>5</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>96.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>2008</td>\n",
       "      <td>4</td>\n",
       "      <td>Western Kentucky</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>39</td>\n",
       "      <td>124</td>\n",
       "      <td>46</td>\n",
       "      <td>25</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>5.30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>2008</td>\n",
       "      <td>3</td>\n",
       "      <td>Winthrop</td>\n",
       "      <td>13</td>\n",
       "      <td>64</td>\n",
       "      <td>108</td>\n",
       "      <td>121</td>\n",
       "      <td>108</td>\n",
       "      <td>93</td>\n",
       "      <td>96.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>99.90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>99.70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1079 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      YEAR  TEAM NO              TEAM  SEED  ROUND  NET RPI  RESUME  WAB RANK  \\\n",
       "0     2024     1079             Akron    14      0      106     131       104   \n",
       "1     2024     1078           Alabama     4      0       10      31        15   \n",
       "2     2024     1077           Arizona     2      0        4      10        11   \n",
       "3     2024     1076            Auburn     4      0        5      45         9   \n",
       "4     2024     1075            Baylor     3      0       13       8        10   \n",
       "...    ...      ...               ...   ...    ...      ...     ...       ...   \n",
       "1074  2008        5     West Virginia     7     16       29      32        28   \n",
       "1075  2008        4  Western Kentucky    12     16       39     124        46   \n",
       "1076  2008        3          Winthrop    13     64      108     121       108   \n",
       "1077  2008        2         Wisconsin     3     16       11       9         8   \n",
       "1078  2008        1            Xavier     3      8        9       7        18   \n",
       "\n",
       "      ELO  B POWER  Q1 W  Q2 W  Q1 PLUS Q2 W  Q3 Q4 L  PLUS 500  R SCORE  \\\n",
       "0     103    111.5     0     2             2        4        13     0.00   \n",
       "1      31     11.5     4     7            11        0        11    99.35   \n",
       "2      14      5.5     8     7            15        1        18    99.87   \n",
       "3       5      4.0     3    10            13        0        21    99.42   \n",
       "4      25     13.5    10     4            14        0        14    99.73   \n",
       "...   ...      ...   ...   ...           ...      ...       ...      ...   \n",
       "1074   29     20.0     3     2             5        1        13    96.80   \n",
       "1075   25     45.0     0     1             1        1        19     5.30   \n",
       "1076   93     96.0     1     2             3        7         9     0.00   \n",
       "1077    5      6.0     6     2             8        0        25    99.90   \n",
       "1078   13     13.0     9     3            12        0        21    99.70   \n",
       "\n",
       "      BID TYPE  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "1074         0  \n",
       "1075         1  \n",
       "1076         1  \n",
       "1077         1  \n",
       "1078         0  \n",
       "\n",
       "[1079 rows x 17 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Feature Selection\n",
    "# Features = SEED, NET RPI, WAB RANK, ELO, B POWER, & PLUS 500\n",
    "# BID TYPE is the target variable\n",
    "X = data[['SEED', 'NET RPI', 'WAB RANK', 'ELO', 'B POWER', 'PLUS 500']]\n",
    "y = data['BID TYPE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Initialize and fit the Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any missing values or infinite values in the data after scaling\n",
    "assert not np.isnan(X_train).any(), \"There are missing values in the training data\"\n",
    "assert not np.isnan(X_test).any(), \"There are missing values in the testing data\"\n",
    "assert not np.isinf(X_train).any(), \"There are infinite values in the training data\"\n",
    "assert not np.isinf(X_test).any(), \"There are infinite values in the testing data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnparentejr/Documents/Final_Project-main/.conda/lib/python3.11/site-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Build the neural network\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(32, activation='relu', input_shape=[len(X_train[0])]),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Compile Model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6165 - loss: 0.6635 - val_accuracy: 0.8150 - val_loss: 0.5591\n",
      "Epoch 2/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7876 - loss: 0.5350 - val_accuracy: 0.8150 - val_loss: 0.4823\n",
      "Epoch 3/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8086 - loss: 0.4699 - val_accuracy: 0.8266 - val_loss: 0.4332\n",
      "Epoch 4/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8422 - loss: 0.4262 - val_accuracy: 0.8439 - val_loss: 0.4010\n",
      "Epoch 5/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.8404 - loss: 0.4178 - val_accuracy: 0.8439 - val_loss: 0.3884\n",
      "Epoch 6/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8227 - loss: 0.3984 - val_accuracy: 0.8439 - val_loss: 0.3795\n",
      "Epoch 7/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8485 - loss: 0.3570 - val_accuracy: 0.8439 - val_loss: 0.3738\n",
      "Epoch 8/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.8573 - loss: 0.3622 - val_accuracy: 0.8497 - val_loss: 0.3716\n",
      "Epoch 9/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.8502 - loss: 0.3806 - val_accuracy: 0.8497 - val_loss: 0.3661\n",
      "Epoch 10/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.8318 - loss: 0.3861 - val_accuracy: 0.8497 - val_loss: 0.3619\n",
      "Epoch 11/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8612 - loss: 0.3586 - val_accuracy: 0.8555 - val_loss: 0.3585\n",
      "Epoch 12/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.8459 - loss: 0.3825 - val_accuracy: 0.8497 - val_loss: 0.3566\n",
      "Epoch 13/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8711 - loss: 0.3164 - val_accuracy: 0.8439 - val_loss: 0.3529\n",
      "Epoch 14/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 924us/step - accuracy: 0.8370 - loss: 0.3803 - val_accuracy: 0.8497 - val_loss: 0.3489\n",
      "Epoch 15/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 860us/step - accuracy: 0.8426 - loss: 0.3757 - val_accuracy: 0.8497 - val_loss: 0.3442\n",
      "Epoch 16/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.8521 - loss: 0.3433 - val_accuracy: 0.8497 - val_loss: 0.3407\n",
      "Epoch 17/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.8558 - loss: 0.3440 - val_accuracy: 0.8497 - val_loss: 0.3354\n",
      "Epoch 18/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.8574 - loss: 0.3478 - val_accuracy: 0.8555 - val_loss: 0.3322\n",
      "Epoch 19/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.8505 - loss: 0.3328 - val_accuracy: 0.8555 - val_loss: 0.3271\n",
      "Epoch 20/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.8771 - loss: 0.3273 - val_accuracy: 0.8555 - val_loss: 0.3231\n",
      "Epoch 21/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.8548 - loss: 0.3350 - val_accuracy: 0.8555 - val_loss: 0.3202\n",
      "Epoch 22/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8606 - loss: 0.3187 - val_accuracy: 0.8497 - val_loss: 0.3172\n",
      "Epoch 23/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.3072 - val_accuracy: 0.8497 - val_loss: 0.3143\n",
      "Epoch 24/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8807 - loss: 0.3142 - val_accuracy: 0.8555 - val_loss: 0.3111\n",
      "Epoch 25/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - accuracy: 0.8865 - loss: 0.2936 - val_accuracy: 0.8497 - val_loss: 0.3075\n",
      "Epoch 26/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8654 - loss: 0.3169 - val_accuracy: 0.8555 - val_loss: 0.3023\n",
      "Epoch 27/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.8781 - loss: 0.2928 - val_accuracy: 0.8555 - val_loss: 0.3032\n",
      "Epoch 28/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 983us/step - accuracy: 0.8783 - loss: 0.3079 - val_accuracy: 0.8555 - val_loss: 0.2987\n",
      "Epoch 29/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8611 - loss: 0.3166 - val_accuracy: 0.8613 - val_loss: 0.2996\n",
      "Epoch 30/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.8704 - loss: 0.3142 - val_accuracy: 0.8728 - val_loss: 0.2943\n",
      "Epoch 31/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 913us/step - accuracy: 0.8751 - loss: 0.2948 - val_accuracy: 0.8613 - val_loss: 0.2917\n",
      "Epoch 32/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8745 - loss: 0.3159 - val_accuracy: 0.8671 - val_loss: 0.2914\n",
      "Epoch 33/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.8561 - loss: 0.3315 - val_accuracy: 0.8671 - val_loss: 0.2891\n",
      "Epoch 34/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.8805 - loss: 0.2950 - val_accuracy: 0.8728 - val_loss: 0.2872\n",
      "Epoch 35/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.8786 - loss: 0.2984 - val_accuracy: 0.8555 - val_loss: 0.2888\n",
      "Epoch 36/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.8836 - loss: 0.2664 - val_accuracy: 0.8613 - val_loss: 0.2843\n",
      "Epoch 37/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8641 - loss: 0.3038 - val_accuracy: 0.8555 - val_loss: 0.2980\n",
      "Epoch 38/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - accuracy: 0.8678 - loss: 0.3096 - val_accuracy: 0.8613 - val_loss: 0.2818\n",
      "Epoch 39/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.8807 - loss: 0.2988 - val_accuracy: 0.8728 - val_loss: 0.2780\n",
      "Epoch 40/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - accuracy: 0.8782 - loss: 0.2908 - val_accuracy: 0.8671 - val_loss: 0.2786\n",
      "Epoch 41/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.8544 - loss: 0.3339 - val_accuracy: 0.8671 - val_loss: 0.2774\n",
      "Epoch 42/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.8639 - loss: 0.3089 - val_accuracy: 0.8786 - val_loss: 0.2803\n",
      "Epoch 43/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8941 - loss: 0.2593 - val_accuracy: 0.8555 - val_loss: 0.2779\n",
      "Epoch 44/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - accuracy: 0.8795 - loss: 0.2813 - val_accuracy: 0.8671 - val_loss: 0.2748\n",
      "Epoch 45/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8524 - loss: 0.3109 - val_accuracy: 0.8728 - val_loss: 0.2738\n",
      "Epoch 46/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.8720 - loss: 0.2912 - val_accuracy: 0.8671 - val_loss: 0.2722\n",
      "Epoch 47/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.8867 - loss: 0.2747 - val_accuracy: 0.8613 - val_loss: 0.2707\n",
      "Epoch 48/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.8695 - loss: 0.2702 - val_accuracy: 0.8671 - val_loss: 0.2699\n",
      "Epoch 49/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.8940 - loss: 0.2545 - val_accuracy: 0.8728 - val_loss: 0.2702\n",
      "Epoch 50/50\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.8787 - loss: 0.2827 - val_accuracy: 0.8728 - val_loss: 0.2707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2bd9c9050>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 9: Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - accuracy: 0.7941 - loss: 0.4309\n",
      "Accuracy: 81.4814805984497%\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Accuracy: {accuracy*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    }
   ],
   "source": [
    "# Step 11: Make predictions\n",
    "predictions = model.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
